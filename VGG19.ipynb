{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBjI_hRY-1Cq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from google.colab import drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn6Yjlsg-_Nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7ed083-56b8-482c-98a5-50c6e0cb9480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (if dataset is stored there)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths to your dataset (adjust according to your dataset path in Google Drive)\n",
        "train_dir = '/content/drive/MyDrive/train'\n",
        "test_dir = '/content/drive/MyDrive/test'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image data preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Loading the images from the directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # VGG19 expects 224x224 input images\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # Assuming binary classification (covid vs normal)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPnVMgNT_5r2",
        "outputId": "e7dc7147-7e61-4811-8a84-d23e029d5906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2754 images belonging to 2 classes.\n",
            "Found 1288 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading the pre-trained VGG19 model without the top classification layer\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freezing the convolutional base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding custom classification layers on top of VGG19\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)  # Output layer for binary classification\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Calculate steps_per_epoch and validation_steps based on dataset size\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = test_generator.samples // test_generator.batch_size\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/vgg19_covid19_classifier.h5')\n",
        "\n",
        "# Optionally: evaluate the model\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "2yAiPZYMAKGZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}